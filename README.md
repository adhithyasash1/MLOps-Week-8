# ğŸ§ª analyzing model robustness under data poisoning

[![build](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/adhithyasash1/adhithyasash1-mlops-week-8/actions)
[![pipeline](https://img.shields.io/badge/dvc-cml--pipeline-blue)](https://dvc.org/doc/cml)
[![storage](https://img.shields.io/badge/data--versioning-enabled-yellow)](https://dvc.org)
[![accuracy](https://img.shields.io/badge/baseline%20accuracy-93.3%25-blue)](baseline_acc.txt)

this project explores how injecting label noise (i.e. "data poisoning") impacts the performance of a machine learning classifier. the pipeline is fully reproducible using `dvc`, tracked using `dvclive`, and runs automatically via `github actions` + `cml`.

---

## ğŸ§  objective

evaluate how the validation accuracy, loss, and f1-score degrade as the **poison rate** (i.e., the fraction of corrupted training labels) increases from 0% to 50%.

---

## ğŸ“‚ directory layout

```
adhithyasash1-mlops-week-8/
â”œâ”€â”€ data/                  â†’ dvc-tracked iris dataset
â”œâ”€â”€ models/                â†’ trained models (output)
â”œâ”€â”€ plots/                 â†’ confusion matrices per run
â”œâ”€â”€ dvclive/               â†’ metrics + plots tracked via dvclive
â”œâ”€â”€ train.py               â†’ full ml pipeline script
â”œâ”€â”€ plot_summary.py        â†’ final summary plot across runs
â”œâ”€â”€ params.yaml            â†’ configurable poison rate
â”œâ”€â”€ dvc.yaml               â†’ pipeline definition
â”œâ”€â”€ .github/workflows/     â†’ github actions + cml pipeline
â”œâ”€â”€ results.csv            â†’ exported run-wise metrics
â”œâ”€â”€ summary_plot.png       â†’ accuracy/loss vs poison rate
```

---

## âš™ï¸ pipeline overview

* ğŸ’¾ **dvc** is used to define stages, manage outputs, and handle experiments
* ğŸ“ˆ **dvclive** tracks key metrics during each run
* ğŸ§ª **github actions** orchestrates multiple experiments via looping `dvc exp run`
* ğŸ§® models trained: logistic regression, random forest, and svm
* ğŸ–¼ï¸ confusion matrices generated for each model
* ğŸ“Š a final summary plot shows trends in accuracy/loss vs. poison rate

---

## ğŸ” experiment automation

the `run.yml` ci workflow:

* pulls dataset via dvc
* runs experiments for poison rates: 0.0, 0.05, 0.10, 0.25, 0.50
* collects metrics via `dvc exp show --csv`
* plots accuracy & loss trends
* creates a markdown report as a cml comment on the pr

---

## ğŸ“‰ key output

### ğŸ”¬ sample summary plot

![summary]([[summary_plot.png](https://camo.githubusercontent.com/6d48b51ea4499518112db7462c96fd1ba18ed93108aee957b7dd9e6b116167fa/68747470733a2f2f61737365742e636d6c2e6465762f656337643038383333353163666536316461386238313466613866303237643064336562613063623f636d6c3d706e672663616368652d6279706173733d31373564373164632d613938362d343238302d626336622d663966306661333234363563)](https://camo.githubusercontent.com/6d48b51ea4499518112db7462c96fd1ba18ed93108aee957b7dd9e6b116167fa/68747470733a2f2f61737365742e636d6c2e6465762f656337643038383333353163666536316461386238313466613866303237643064336562613063623f636d6c3d706e672663616368652d6279706173733d31373564373164632d613938362d343238302d626336622d663966306661333234363563))

### ğŸ“Š baseline accuracy

extracted and stored in `baseline_acc.txt`: **93.3%**

---

## ğŸ“¥ run it locally

```bash
# install dependencies
pip install -r requirements.txt

# run a single experiment
dvc exp run --set-param train.poison_rate=0.25

# export metrics
dvc exp show --csv > results.csv

# generate plot
python plot_summary.py
```

---

## ğŸ™‹â€â™‚ï¸ author

R Sashi Adhithya (21F3000611)
github: [@adhithyasash1](https://github.com/adhithyasash1)
